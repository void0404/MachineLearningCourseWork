{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 避免pandas显示不全的问题，此处设置pandas显示的行数200，列不做限制，便于观察每个维度的信息\n",
    "pd.options.display.max_rows=None\n",
    "pd.options.display.max_columns=40\n",
    "pd.set_option('float_format', lambda x: '%.3f' % x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#处理中需要用的函数，\n",
    "def workYearDIc(x):\n",
    "    if str(x) == 'nan':\n",
    "        return 0\n",
    "    x = x.replace('< 1', '0')\n",
    "    return int(re.search('(\\d+)', x).group())\n",
    "\n",
    "\n",
    "def findDig(val):\n",
    "    fd = re.search('(\\d+-)', val)\n",
    "    if fd is None:\n",
    "        return '1-' + val\n",
    "    return val + '-01'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 统计df的缺失值，并显示缺失比例\n",
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "    print(\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n",
    "                                                              \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################第0步数据预处理#############################\n"
     ]
    }
   ],
   "source": [
    "#加载全部数据集\n",
    "print('######################第0步数据预处理#############################')\n",
    "train_data = pd.read_csv('datasets/train_public.csv')\n",
    "test_public = pd.read_csv('datasets/test_public.csv')\n",
    "train_inte = pd.read_csv('datasets/train_internet.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "          loan_id    user_id  total_loan  year_of_loan  interest  \\\ncount   10000.000  10000.000   10000.000     10000.000 10000.000   \nmean  1025209.588 225209.588   14402.127         3.480    13.223   \nstd     14386.821  14386.821    8953.947         0.854     4.876   \nmin   1000008.000 200008.000     818.182         3.000     4.779   \n25%   1012973.250 212973.250    7500.000         3.000     9.702   \n50%   1025276.500 225276.500   12272.727         3.000    12.639   \n75%   1037694.500 237694.500   19636.364         3.000    15.986   \nmax   1049997.000 249997.000   47272.727         5.000    33.979   \n\n       monthly_payment  house_exist  censor_status       use  post_code  \\\ncount        10000.000    10000.000      10000.000 10000.000  10000.000   \nmean           436.960        0.612          1.015     1.763    257.519   \nstd            261.754        0.672          0.788     2.392    201.352   \nmin             30.440        0.000          0.000     0.000      0.000   \n25%            248.820        0.000          0.000     0.000     99.000   \n50%            371.525        1.000          1.000     0.000    197.000   \n75%            573.830        1.000          2.000     4.000    390.000   \nmax           1503.890        4.000          2.000    13.000    901.000   \n\n         region  debt_loan_ratio  del_in_18month  scoring_low  scoring_high  \\\ncount 10000.000        10000.000       10000.000    10000.000     10000.000   \nmean     16.320           17.532           0.312      664.116       774.448   \nstd      11.019           14.219           0.872       77.041        99.174   \nmin       0.000            0.000           0.000      540.000       585.000   \n25%       8.000           11.158           0.000      601.364       700.000   \n50%      14.000           16.652           0.000      665.000       772.727   \n75%      22.000           22.782           0.000      725.455       845.000   \nmax      49.000          999.000          15.000      910.909      1131.818   \n\n       known_outstanding_loan  known_dero  pub_dero_bankrup  recircle_b  \\\ncount               10000.000   10000.000          9993.000   10000.000   \nmean                   11.645       0.226             0.139   16548.299   \nstd                     5.501       0.608             0.379   21078.544   \nmin                     1.000       0.000             0.000       0.000   \n25%                     8.000       0.000             0.000    6189.173   \n50%                    11.000       0.000             0.000   11476.077   \n75%                    14.000       0.000             0.000   20384.077   \nmax                    59.000      12.000             5.000  779021.000   \n\n       recircle_u  initial_list_status  app_type     title  policy_code  \\\ncount   10000.000            10000.000 10000.000 10000.000    10000.000   \nmean       53.623                0.414     0.020  1808.202        1.000   \nstd        26.024                0.493     0.140  8011.098        0.000   \nmin         0.000                0.000     0.000     0.000        1.000   \n25%        33.969                0.000     0.000     0.000        1.000   \n50%        53.281                0.000     0.000     1.000        1.000   \n75%        73.310                1.000     0.000     5.000        1.000   \nmax       120.615                1.000     1.000 61387.000        1.000   \n\n            f0       f1       f2       f3       f4  early_return  \\\ncount 9502.000 9142.000 9502.000 9502.000 9502.000     10000.000   \nmean     5.690    0.001    8.468   14.659    8.098         1.291   \nstd      3.299    0.038    7.316    8.264    4.872         1.449   \nmin      0.000    0.000    0.000    2.000    0.000         0.000   \n25%      3.000    0.000    4.000    9.000    5.000         0.000   \n50%      5.000    0.000    7.000   13.000    7.000         1.000   \n75%      7.000    0.000   11.000   19.000   11.000         3.000   \nmax     33.000    1.000   93.000   88.000   50.000         5.000   \n\n       early_return_amount  early_return_amount_3mon  isDefault  \ncount            10000.000                 10000.000  10000.000  \nmean              2173.916                   335.232      0.168  \nstd               3027.540                   635.109      0.374  \nmin                  0.000                     0.000      0.000  \n25%                  0.000                     0.000      0.000  \n50%                838.500                     0.000      0.000  \n75%               3354.250                   413.675      0.000  \nmax              18413.000                  5523.900      1.000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_id</th>\n      <th>user_id</th>\n      <th>total_loan</th>\n      <th>year_of_loan</th>\n      <th>interest</th>\n      <th>monthly_payment</th>\n      <th>house_exist</th>\n      <th>censor_status</th>\n      <th>use</th>\n      <th>post_code</th>\n      <th>region</th>\n      <th>debt_loan_ratio</th>\n      <th>del_in_18month</th>\n      <th>scoring_low</th>\n      <th>scoring_high</th>\n      <th>known_outstanding_loan</th>\n      <th>known_dero</th>\n      <th>pub_dero_bankrup</th>\n      <th>recircle_b</th>\n      <th>recircle_u</th>\n      <th>initial_list_status</th>\n      <th>app_type</th>\n      <th>title</th>\n      <th>policy_code</th>\n      <th>f0</th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>early_return</th>\n      <th>early_return_amount</th>\n      <th>early_return_amount_3mon</th>\n      <th>isDefault</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>9993.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>9502.000</td>\n      <td>9142.000</td>\n      <td>9502.000</td>\n      <td>9502.000</td>\n      <td>9502.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n      <td>10000.000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1025209.588</td>\n      <td>225209.588</td>\n      <td>14402.127</td>\n      <td>3.480</td>\n      <td>13.223</td>\n      <td>436.960</td>\n      <td>0.612</td>\n      <td>1.015</td>\n      <td>1.763</td>\n      <td>257.519</td>\n      <td>16.320</td>\n      <td>17.532</td>\n      <td>0.312</td>\n      <td>664.116</td>\n      <td>774.448</td>\n      <td>11.645</td>\n      <td>0.226</td>\n      <td>0.139</td>\n      <td>16548.299</td>\n      <td>53.623</td>\n      <td>0.414</td>\n      <td>0.020</td>\n      <td>1808.202</td>\n      <td>1.000</td>\n      <td>5.690</td>\n      <td>0.001</td>\n      <td>8.468</td>\n      <td>14.659</td>\n      <td>8.098</td>\n      <td>1.291</td>\n      <td>2173.916</td>\n      <td>335.232</td>\n      <td>0.168</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14386.821</td>\n      <td>14386.821</td>\n      <td>8953.947</td>\n      <td>0.854</td>\n      <td>4.876</td>\n      <td>261.754</td>\n      <td>0.672</td>\n      <td>0.788</td>\n      <td>2.392</td>\n      <td>201.352</td>\n      <td>11.019</td>\n      <td>14.219</td>\n      <td>0.872</td>\n      <td>77.041</td>\n      <td>99.174</td>\n      <td>5.501</td>\n      <td>0.608</td>\n      <td>0.379</td>\n      <td>21078.544</td>\n      <td>26.024</td>\n      <td>0.493</td>\n      <td>0.140</td>\n      <td>8011.098</td>\n      <td>0.000</td>\n      <td>3.299</td>\n      <td>0.038</td>\n      <td>7.316</td>\n      <td>8.264</td>\n      <td>4.872</td>\n      <td>1.449</td>\n      <td>3027.540</td>\n      <td>635.109</td>\n      <td>0.374</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1000008.000</td>\n      <td>200008.000</td>\n      <td>818.182</td>\n      <td>3.000</td>\n      <td>4.779</td>\n      <td>30.440</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>540.000</td>\n      <td>585.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1012973.250</td>\n      <td>212973.250</td>\n      <td>7500.000</td>\n      <td>3.000</td>\n      <td>9.702</td>\n      <td>248.820</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>99.000</td>\n      <td>8.000</td>\n      <td>11.158</td>\n      <td>0.000</td>\n      <td>601.364</td>\n      <td>700.000</td>\n      <td>8.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>6189.173</td>\n      <td>33.969</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>3.000</td>\n      <td>0.000</td>\n      <td>4.000</td>\n      <td>9.000</td>\n      <td>5.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1025276.500</td>\n      <td>225276.500</td>\n      <td>12272.727</td>\n      <td>3.000</td>\n      <td>12.639</td>\n      <td>371.525</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>197.000</td>\n      <td>14.000</td>\n      <td>16.652</td>\n      <td>0.000</td>\n      <td>665.000</td>\n      <td>772.727</td>\n      <td>11.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>11476.077</td>\n      <td>53.281</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>5.000</td>\n      <td>0.000</td>\n      <td>7.000</td>\n      <td>13.000</td>\n      <td>7.000</td>\n      <td>1.000</td>\n      <td>838.500</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1037694.500</td>\n      <td>237694.500</td>\n      <td>19636.364</td>\n      <td>3.000</td>\n      <td>15.986</td>\n      <td>573.830</td>\n      <td>1.000</td>\n      <td>2.000</td>\n      <td>4.000</td>\n      <td>390.000</td>\n      <td>22.000</td>\n      <td>22.782</td>\n      <td>0.000</td>\n      <td>725.455</td>\n      <td>845.000</td>\n      <td>14.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>20384.077</td>\n      <td>73.310</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>5.000</td>\n      <td>1.000</td>\n      <td>7.000</td>\n      <td>0.000</td>\n      <td>11.000</td>\n      <td>19.000</td>\n      <td>11.000</td>\n      <td>3.000</td>\n      <td>3354.250</td>\n      <td>413.675</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1049997.000</td>\n      <td>249997.000</td>\n      <td>47272.727</td>\n      <td>5.000</td>\n      <td>33.979</td>\n      <td>1503.890</td>\n      <td>4.000</td>\n      <td>2.000</td>\n      <td>13.000</td>\n      <td>901.000</td>\n      <td>49.000</td>\n      <td>999.000</td>\n      <td>15.000</td>\n      <td>910.909</td>\n      <td>1131.818</td>\n      <td>59.000</td>\n      <td>12.000</td>\n      <td>5.000</td>\n      <td>779021.000</td>\n      <td>120.615</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>61387.000</td>\n      <td>1.000</td>\n      <td>33.000</td>\n      <td>1.000</td>\n      <td>93.000</td>\n      <td>88.000</td>\n      <td>50.000</td>\n      <td>5.000</td>\n      <td>18413.000</td>\n      <td>5523.900</td>\n      <td>1.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 对部分存在缺失值的维度进行补全，采用median补全方式，并对f0-f4进行求平均扩征维度\n",
    "# 循环额度利用率,公开记录清除的数量,债务收入比\n",
    "loss_numerical_feas = ['recircle_u', 'pub_dero_bankrup', 'debt_loan_ratio']\n",
    "f_feas = ['f0', 'f1', 'f2', 'f3', 'f4']\n",
    "# 采用中位数填充loss_numerical_feas和f_feas\n",
    "train_data[loss_numerical_feas] = train_data[loss_numerical_feas].fillna(train_data[loss_numerical_feas].median())\n",
    "train_data[f_feas] = train_data[f_feas].fillna(train_data[f_feas].median())\n",
    "train_data['post_code'] = train_data['post_code'].fillna(train_data['post_code'].mode()[0])\n",
    "# 债务比小于0\n",
    "train_data.loc[train_data['debt_loan_ratio'] <= 0, 'debt_loan_ratio'] = 0\n",
    "for f in f_feas:\n",
    "    train_data[f'industry_to_mean_{f}'] = train_data.groupby('industry')[f].transform('mean')\n",
    "# 其他数据上同样使用该数据处理\n",
    "test_public[loss_numerical_feas] = test_public[loss_numerical_feas].fillna(test_public[loss_numerical_feas].median())\n",
    "test_public['post_code'] = test_public['post_code'].fillna(test_public['post_code'].mode()[0])\n",
    "test_public.loc[test_public['debt_loan_ratio'] <= 0, 'debt_loan_ratio'] = 0\n",
    "test_public[f_feas] = test_public[f_feas].fillna(test_public[f_feas].median())\n",
    "for f in f_feas:\n",
    "    test_public[f'industry_to_mean_{f}'] = test_public.groupby('industry')[f].transform('mean')\n",
    "\n",
    "train_inte[loss_numerical_feas] = train_inte[loss_numerical_feas].fillna(train_inte[loss_numerical_feas].median())\n",
    "train_inte['post_code'] = train_inte['post_code'].fillna(train_inte['post_code'].mode()[0])\n",
    "train_inte['title'] = train_inte['title'].fillna(train_inte['title'].mode()[0])\n",
    "train_inte.loc[train_inte['debt_loan_ratio'] <= 0, 'debt_loan_ratio'] = 0\n",
    "train_inte[f_feas] = train_inte[f_feas].fillna(train_inte[f_feas].median())\n",
    "for f in f_feas:\n",
    "    train_inte[f'industry_to_mean_{f}'] = train_inte.groupby('industry')[f].transform('mean')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 时间数据处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 网贷等级\n",
    "class_dict = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'C': 3,\n",
    "    'D': 4,\n",
    "    'E': 5,\n",
    "    'F': 6,\n",
    "    'G': 7,\n",
    "}\n",
    "\n",
    "timeMax = pd.to_datetime('1-Dec-21')\n",
    "train_data['work_year'] = train_data['work_year'].map(workYearDIc)\n",
    "\n",
    "test_public['work_year'] = test_public['work_year'].map(workYearDIc)\n",
    "\n",
    "train_data['class'] = train_data['class'].map(class_dict)\n",
    "test_public['class'] = test_public['class'].map(class_dict)\n",
    "\n",
    "train_data['earlies_credit_mon'] = pd.to_datetime(train_data['earlies_credit_mon'].map(findDig))\n",
    "test_public['earlies_credit_mon'] = pd.to_datetime(test_public['earlies_credit_mon'].map(findDig))\n",
    "\n",
    "train_data.loc[train_data['earlies_credit_mon'] > timeMax, 'earlies_credit_mon'] = train_data.loc[train_data[\n",
    "                                                                                                      'earlies_credit_mon'] > timeMax, 'earlies_credit_mon'] + pd.offsets.DateOffset(years=-100)\n",
    "test_public.loc[test_public['earlies_credit_mon'] > timeMax, 'earlies_credit_mon'] = test_public.loc[test_public[\n",
    "                                                                                                         'earlies_credit_mon'] > timeMax, 'earlies_credit_mon'] + pd.offsets.DateOffset(\n",
    "    years=-100)\n",
    "train_data['issue_date'] = pd.to_datetime(train_data['issue_date'])\n",
    "test_public['issue_date'] = pd.to_datetime(test_public['issue_date'])\n",
    "\n",
    "# Internet数据处理\n",
    "train_inte['work_year'] = train_inte['work_year'].map(workYearDIc)\n",
    "train_inte['class'] = train_inte['class'].map(class_dict)\n",
    "\n",
    "train_inte['earlies_credit_mon'] = pd.to_datetime(train_inte['earlies_credit_mon'])\n",
    "train_inte['issue_date'] = pd.to_datetime(train_inte['issue_date'])\n",
    "\n",
    "train_data['issue_date_month'] = train_data['issue_date'].dt.month\n",
    "train_data['issue_date_year'] = train_data['issue_date'].dt.year\n",
    "test_public['issue_date_month'] = test_public['issue_date'].dt.month\n",
    "test_public['issue_date_year'] = test_public['issue_date'].dt.year\n",
    "train_data['issue_date_dayofweek'] = train_data['issue_date'].dt.dayofweek\n",
    "test_public['issue_date_dayofweek'] = test_public['issue_date'].dt.dayofweek\n",
    "\n",
    "train_data['earliesCreditMon'] = train_data['earlies_credit_mon'].dt.month\n",
    "test_public['earliesCreditMon'] = test_public['earlies_credit_mon'].dt.month\n",
    "train_data['earliesCreditYear'] = train_data['earlies_credit_mon'].dt.year\n",
    "test_public['earliesCreditYear'] = test_public['earlies_credit_mon'].dt.year\n",
    "\n",
    "train_inte['issue_date_month'] = train_inte['issue_date'].dt.month\n",
    "train_inte['issue_date_dayofweek'] = train_inte['issue_date'].dt.dayofweek\n",
    "train_inte['issue_date_year'] = train_inte['issue_date'].dt.year\n",
    "\n",
    "train_inte['earliesCreditMon'] = train_inte['earlies_credit_mon'].dt.month\n",
    "train_inte['earliesCreditYear'] = train_inte['earlies_credit_mon'].dt.year\n",
    "\n",
    "###########################编码处理\n",
    "\n",
    "cat_cols = ['employer_type', 'industry']\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "for col in cat_cols:\n",
    "    lbl = LabelEncoder().fit(train_data[col])\n",
    "    train_data[col] = lbl.transform(train_data[col])\n",
    "    test_public[col] = lbl.transform(test_public[col])\n",
    "    train_inte[col] = lbl.transform(train_inte[col])\n",
    "\n",
    "col_to_drop = ['issue_date', 'earlies_credit_mon']\n",
    "train_data = train_data.drop(col_to_drop, axis=1)\n",
    "test_public = test_public.drop(col_to_drop, axis=1)\n",
    "train_inte = train_inte.drop(col_to_drop, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B5' 'C3' 'D2' 'B1' 'C5' 'A5' 'C1' 'B4' 'A1' 'D1' 'C4' 'E2' 'C2' 'D4'\n",
      " 'E3' 'D3' 'A4' 'B3' 'A3' 'E5' 'B2' 'G5' 'A2' 'F3' 'D5' 'E1' 'F4' 'F1'\n",
      " 'F5' 'F2' 'G1' 'E4' 'G2' 'G3' 'G4']\n",
      "[3 1 2 4 5 6 7]\n",
      "[2 3 4 1 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "###subclass，这个维度应该比较关键不能直接干掉而需要补充\n",
    "print(train_inte['sub_class'].unique())\n",
    "print(train_data['class'].unique())\n",
    "print(test_public['class'].unique())\n",
    "'''\n",
    "['A1' 'A2' 'A3' 'A4' 'A5' 'B1' 'B2' 'B3' 'B4' 'B5' 'C1' 'C2' 'C3' 'C4' 'C5' 'D1' 'D2' 'D3' 'D4' 'D5' 'E1' 'E2'\n",
    "'E3' 'E4' 'E5' 'F1' 'F2' 'F3' 'F4' 'F5' 'G1' 'G2' 'G3' 'G4' 'G5']\n",
    "共七大类其中每大类中有五小类，采用聚类方案\n",
    "'''\n",
    "\n",
    "\n",
    "def feature_Kmeans(data, label):\n",
    "    mms = MinMaxScaler()\n",
    "    feats = [f for f in data.columns if f not in ['loan_id', 'user_id', 'isDefault']]\n",
    "    data = data[feats]\n",
    "    mmsModel = mms.fit_transform(data.loc[data['class'] == label])\n",
    "    clf = KMeans(5, random_state=2022)\n",
    "    pre = clf.fit(mmsModel)\n",
    "    test = pre.labels_\n",
    "    final_data = pd.Series(test, index=data.loc[data['class'] == label].index)\n",
    "    if label == 1:\n",
    "        final_data = final_data.map({0: 'A1', 1: 'A2', 2: 'A3', 3: 'A4', 4: 'A5'})\n",
    "    elif label == 2:\n",
    "        final_data = final_data.map({0: 'B1', 1: 'B2', 2: 'B3', 3: 'B4', 4: 'B5'})\n",
    "    elif label == 3:\n",
    "        final_data = final_data.map({0: 'C1', 1: 'C2', 2: 'C3', 3: 'C4', 4: 'C5'})\n",
    "    elif label == 4:\n",
    "        final_data = final_data.map({0: 'D1', 1: 'D2', 2: 'D3', 3: 'D4', 4: 'D5'})\n",
    "    elif label == 5:\n",
    "        final_data = final_data.map({0: 'E1', 1: 'E2', 2: 'E3', 3: 'E4', 4: 'E5'})\n",
    "    elif label == 6:\n",
    "        final_data = final_data.map({0: 'F1', 1: 'F2', 2: 'F3', 3: 'F4', 4: 'F5'})\n",
    "    elif label == 7:\n",
    "        final_data = final_data.map({0: 'G1', 1: 'G2', 2: 'G3', 3: 'G4', 4: 'G5'})\n",
    "    return final_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=7.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "E:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 训练集合并\n",
    "train_data1 = feature_Kmeans(train_data, 1)\n",
    "train_data2 = feature_Kmeans(train_data, 2)\n",
    "train_data3 = feature_Kmeans(train_data, 3)\n",
    "train_data4 = feature_Kmeans(train_data, 4)\n",
    "train_data5 = feature_Kmeans(train_data, 5)\n",
    "train_data6 = feature_Kmeans(train_data, 6)\n",
    "train_data7 = feature_Kmeans(train_data, 7)\n",
    "\n",
    "train_dataall = pd.concat(\n",
    "    [train_data1, train_data2, train_data3, train_data4, train_data5, train_data6, train_data7]).reset_index(drop=True)\n",
    "\n",
    "train_data['sub_class'] = train_dataall\n",
    "# 测试集合并\n",
    "test_data1 = feature_Kmeans(test_public, 1)\n",
    "test_data2 = feature_Kmeans(test_public, 2)\n",
    "test_data3 = feature_Kmeans(test_public, 3)\n",
    "test_data4 = feature_Kmeans(test_public, 4)\n",
    "test_data5 = feature_Kmeans(test_public, 5)\n",
    "test_data6 = feature_Kmeans(test_public, 6)\n",
    "test_data7 = feature_Kmeans(test_public, 7)\n",
    "test_dataall = pd.concat(\n",
    "    [test_data1, test_data2, test_data3, test_data4, test_data5, test_data6, test_data7]).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "test_public['sub_class'] = test_dataall\n",
    "\n",
    "cat_cols = ['sub_class']\n",
    "for col in cat_cols:\n",
    "    lbl = LabelEncoder().fit(train_data[col])\n",
    "    train_data[col] = lbl.transform(train_data[col])\n",
    "    test_public[col] = lbl.transform(test_public[col])\n",
    "    train_inte[col] = lbl.transform(train_inte[col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\2065274174.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['early_return_amount_early_return'][np.isinf(train_data['early_return_amount_early_return'])] = 0\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\2065274174.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_public['early_return_amount_early_return'][np.isinf(test_public['early_return_amount_early_return'])] = 0\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\2065274174.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_inte['early_return_amount_early_return'][np.isinf(train_inte['early_return_amount_early_return'])] = 0\n"
     ]
    }
   ],
   "source": [
    "#######尝试新的特征######################\n",
    "train_data['post_code_interst_mean'] = train_data.groupby(['post_code'])['interest'].transform('mean')\n",
    "train_inte['post_code_interst_mean'] = train_inte.groupby(['post_code'])['interest'].transform('mean')\n",
    "test_public['post_code_interst_mean'] = test_public.groupby(['post_code'])['interest'].transform('mean')\n",
    "\n",
    "train_data['industry_mean_interest'] = train_data.groupby(['industry'])['interest'].transform('mean')\n",
    "train_inte['industry_mean_interest'] = train_inte.groupby(['industry'])['interest'].transform('mean')\n",
    "test_public['industry_mean_interest'] = test_public.groupby(['industry'])['interest'].transform('mean')\n",
    "\n",
    "train_data['recircle_u_b_std'] = train_data.groupby(['recircle_u'])['recircle_b'].transform('std')\n",
    "test_public['recircle_u_b_std'] = test_public.groupby(['recircle_u'])['recircle_b'].transform('std')\n",
    "train_inte['recircle_u_b_std'] = train_inte.groupby(['recircle_u'])['recircle_b'].transform('std')\n",
    "train_data['early_return_amount_early_return'] = train_data['early_return_amount'] / train_data['early_return']\n",
    "test_public['early_return_amount_early_return'] = test_public['early_return_amount'] / test_public['early_return']\n",
    "train_inte['early_return_amount_early_return'] = train_inte['early_return_amount'] / train_inte['early_return']\n",
    "# 可能出现极大值和空值\n",
    "train_data['early_return_amount_early_return'][np.isinf(train_data['early_return_amount_early_return'])] = 0\n",
    "test_public['early_return_amount_early_return'][np.isinf(test_public['early_return_amount_early_return'])] = 0\n",
    "train_inte['early_return_amount_early_return'][np.isinf(train_inte['early_return_amount_early_return'])] = 0\n",
    "# 还款利息\n",
    "train_data['total_loan_monthly_payment'] = train_data['monthly_payment'] * train_data['year_of_loan'] * 12 - train_data[\n",
    "    'total_loan']\n",
    "test_public['total_loan_monthly_payment'] = test_public['monthly_payment'] * test_public['year_of_loan'] * 12 - \\\n",
    "                                            test_public['total_loan']\n",
    "train_inte['total_loan_monthly_payment'] = train_inte['monthly_payment'] * train_inte['year_of_loan'] * 12 - train_inte[\n",
    "    'total_loan']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
      "C:\\Users\\carculator\\AppData\\Local\\Temp\\ipykernel_25408\\1906598163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'isDefault'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mE:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3629\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3628\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3630\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mE:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mE:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'isDefault'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 39>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m train, train_inte, test\n\u001B[0;32m     38\u001B[0m features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhouse_exist\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdebt_loan_ratio\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindustry\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 39\u001B[0m train_data, train_inte, test_public \u001B[38;5;241m=\u001B[39m \u001B[43mgen_target_encoding_feats\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_inte\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_public\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m                                                                \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43misDefault\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_fold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36mgen_target_encoding_feats\u001B[1;34m(train, train_inte, test, encode_cols, target_col, n_fold)\u001B[0m\n\u001B[0;32m     19\u001B[0m tg_feats \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((train_inte\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlen\u001B[39m(encode_cols)))\n\u001B[0;32m     20\u001B[0m kfold \u001B[38;5;241m=\u001B[39m StratifiedKFold(n_splits\u001B[38;5;241m=\u001B[39mn_fold, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, (train_index, val_index) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(kfold\u001B[38;5;241m.\u001B[39msplit(train_inte[encode_cols], \u001B[43mtrain_inte\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget_col\u001B[49m\u001B[43m]\u001B[49m)):\n\u001B[0;32m     22\u001B[0m     df_train, df_val \u001B[38;5;241m=\u001B[39m train_inte\u001B[38;5;241m.\u001B[39miloc[train_index], train_inte\u001B[38;5;241m.\u001B[39miloc[val_index]\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(encode_cols):\n",
      "File \u001B[1;32mE:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mE:\\ancaconda2\\envs\\pytorch5\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3631\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   3629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3630\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3631\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3632\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3633\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3634\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3635\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3636\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'isDefault'"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "# K折目标编码\n",
    "def gen_target_encoding_feats(train, train_inte, test, encode_cols, target_col, n_fold=10):\n",
    "    '''生成target encoding特征'''\n",
    "    # for training set - cv\n",
    "    tg_feats = np.zeros((train.shape[0], len(encode_cols)))\n",
    "    kfold = StratifiedKFold(n_splits=n_fold, random_state=1024, shuffle=True)\n",
    "    for _, (train_index, val_index) in enumerate(kfold.split(train[encode_cols], train[target_col])):\n",
    "        df_train, df_val = train.iloc[train_index], train.iloc[val_index]\n",
    "        for idx, col in enumerate(encode_cols):\n",
    "            target_mean_dict = df_train.groupby(col)[target_col].mean()\n",
    "            df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
    "            tg_feats[val_index, idx] = df_val[f'{col}_mean_target'].values\n",
    "\n",
    "    for idx, encode_col in enumerate(encode_cols):\n",
    "        train[f'{encode_col}_mean_target'] = tg_feats[:, idx]\n",
    "\n",
    "    # for train_inte set - cv\n",
    "    tg_feats = np.zeros((train_inte.shape[0], len(encode_cols)))\n",
    "    kfold = StratifiedKFold(n_splits=n_fold, random_state=1024, shuffle=True)\n",
    "    for _, (train_index, val_index) in enumerate(kfold.split(train_inte[encode_cols], train_inte[target_col])):\n",
    "        df_train, df_val = train_inte.iloc[train_index], train_inte.iloc[val_index]\n",
    "        for idx, col in enumerate(encode_cols):\n",
    "            target_mean_dict = df_train.groupby(col)[target_col].mean()\n",
    "            df_val[f'{col}_mean_target'] = df_val[col].map(target_mean_dict)\n",
    "            tg_feats[val_index, idx] = df_val[f'{col}_mean_target'].values\n",
    "    for idx, encode_col in enumerate(encode_cols):\n",
    "        train_inte[f'{encode_col}_mean_target'] = tg_feats[:, idx]\n",
    "\n",
    "    # for testing set\n",
    "    for col in encode_cols:\n",
    "        target_mean_dict = train.groupby(col)[target_col].mean()\n",
    "        test[f'{col}_mean_target'] = test[col].map(target_mean_dict)\n",
    "\n",
    "    return train, train_inte, test\n",
    "\n",
    "\n",
    "features = ['house_exist', 'debt_loan_ratio', 'industry', 'title']\n",
    "train_data, train_inte, test_public = gen_target_encoding_feats(train_data, train_inte, test_public, features,\n",
    "                                                                'isDefault', n_fold=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "########################样本扩充\n",
    "def fiterDataModel(data_, test_, y_, folds_):\n",
    "    oof_preds = np.zeros(data_.shape[0])\n",
    "    sub_preds = np.zeros(test_.shape[0])\n",
    "    feats = [f for f in data_.columns if f not in ['loan_id', 'user_id', 'isDefault']]\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n",
    "        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n",
    "        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=4000,\n",
    "            # learning_rate=0.08,\n",
    "            learning_rate=0.06,\n",
    "            num_leaves=2 ** 5,\n",
    "            colsample_bytree=.65,\n",
    "            subsample=.9,\n",
    "            max_depth=5,\n",
    "            reg_alpha=.3,\n",
    "            reg_lambda=.3,\n",
    "            min_split_gain=.01,\n",
    "            min_child_weight=2,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        clf.fit(trn_x, trn_y,\n",
    "                eval_set=[(trn_x, trn_y.astype(int)), (val_x, val_y.astype(int))],\n",
    "                eval_metric='auc', verbose=100, early_stopping_rounds=40  # 40\n",
    "                )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_[feats], num_iteration=clf.best_iteration_)[:, 1] / folds_.n_splits\n",
    "\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "        del clf, trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(y_, oof_preds))\n",
    "\n",
    "    test_['isDefault'] = sub_preds\n",
    "\n",
    "    return test_[['loan_id', 'isDefault']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tr_cols = set(train_data.columns)\n",
    "same_col = list(tr_cols.intersection(set(train_inte.columns)))\n",
    "train_inteSame = train_inte[same_col].copy()\n",
    "Inte_add_cos = list(tr_cols.difference(set(same_col)))\n",
    "for col in Inte_add_cos:\n",
    "    train_inteSame[col] = np.nan\n",
    "y = train_data['isDefault']\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "IntePre = fiterDataModel(train_data, train_inteSame, y, folds)\n",
    "IntePre['isDef'] = train_inte['isDefault']\n",
    "print(roc_auc_score(IntePre['isDef'], IntePre.isDefault))\n",
    "## 选择阈值0.05，从internet表中提取预测小于该概率的样本，并对不同来源的样本赋予来源值\n",
    "InteId = IntePre.loc[IntePre.isDefault < 0.5, 'loan_id'].tolist()\n",
    "train_inteSame['isDefault'] = train_inte['isDefault']\n",
    "use_te = train_inteSame[train_inteSame.loan_id.isin(InteId)].copy()\n",
    "data = pd.concat([train_data, test_public, use_te]).reset_index(drop=True)\n",
    "print('dataShape:', len(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###############开始最后一步的训练\n",
    "def XGBModel(data_, test_, y_, folds_):\n",
    "    oof_preds = np.zeros(data_.shape[0])\n",
    "    sub_preds = np.zeros(test_.shape[0])\n",
    "    feats = [f for f in data_.columns if f not in ['loan_id', 'user_id', 'isDefault']]\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n",
    "        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n",
    "        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n",
    "        clf = XGBClassifier(eval_metric='auc', max_depth=5, alpha=0.3, reg_lambda=0.3, subsample=0.8,\n",
    "                            colsample_bylevel=0.867, objective='binary:logistic', use_label_encoder=False,\n",
    "                            learning_rate=0.08, n_estimators=4000, min_child_weight=2, tree_method='hist',\n",
    "                            n_jobs=-1)\n",
    "        clf.fit(trn_x, trn_y,\n",
    "                eval_set=[(trn_x, trn_y), (val_x, val_y)],\n",
    "                eval_metric='auc', verbose=100, early_stopping_rounds=40  # 40\n",
    "                )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict_proba(val_x, ntree_limit=clf.best_ntree_limit)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_[feats], ntree_limit=clf.best_ntree_limit)[:, 1] / folds_.n_splits\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "        del clf, trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(y_, oof_preds))\n",
    "\n",
    "    test_['isDefault'] = sub_preds\n",
    "    return test_[['loan_id', 'isDefault']]\n",
    "\n",
    "\n",
    "def LGBModel(data_, test_, y_, folds_):\n",
    "    oof_preds = np.zeros(data_.shape[0])\n",
    "    sub_preds = np.zeros(test_.shape[0])\n",
    "    feats = [f for f in data_.columns if f not in ['loan_id', 'user_id', 'isDefault']]\n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_)):\n",
    "        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n",
    "        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=4000,\n",
    "            # learning_rate=0.08,\n",
    "            learning_rate=0.06,\n",
    "            num_leaves=2 ** 5,\n",
    "            colsample_bytree=.65,\n",
    "            subsample=.9,\n",
    "            max_depth=5,\n",
    "            reg_alpha=.3,\n",
    "            reg_lambda=.3,\n",
    "            min_split_gain=.01,\n",
    "            min_child_weight=2,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )\n",
    "        clf.fit(trn_x, trn_y,\n",
    "                eval_set=[(trn_x, trn_y.astype(int)), (val_x, val_y.astype(int))],\n",
    "                eval_metric='auc', verbose=100, early_stopping_rounds=40  # 40\n",
    "                )\n",
    "\n",
    "        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_[feats], num_iteration=clf.best_iteration_)[:, 1] / folds_.n_splits\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n",
    "        del clf, trn_x, trn_y, val_x, val_y\n",
    "        gc.collect()\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(y_, oof_preds))\n",
    "\n",
    "    test_['isDefault'] = sub_preds\n",
    "    return test_[['loan_id', 'isDefault']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = data[data['isDefault'].notna()]\n",
    "test = data[data['isDefault'].isna()]\n",
    "y = train['isDefault']\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=546789)\n",
    "test_preds = LGBModel(train, test, y, folds)\n",
    "test_preds.rename({'loan_id': 'id'}, axis=1)[['id', 'isDefault']].to_csv('baseline8995_.csv', index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}